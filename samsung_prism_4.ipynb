{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "14554b1f9c4c4e369a3ba3bba88dc14a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05dc222f99cc46ed87929aad87be1076",
              "IPY_MODEL_946320ac58514a08a122f47dd66e32c3",
              "IPY_MODEL_8bc22ca988f04e13bd6c81d330380007"
            ],
            "layout": "IPY_MODEL_1437800607304bcdaf96b0ac4a0dc7ae"
          }
        },
        "05dc222f99cc46ed87929aad87be1076": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5231f813a803401ebc5126d3881d751b",
            "placeholder": "​",
            "style": "IPY_MODEL_8c403273055f40c2b834aba1e8c77314",
            "value": "Generating train split: "
          }
        },
        "946320ac58514a08a122f47dd66e32c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b87fcc0d692f4632b6870adeb52a1baa",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9aa9352ca1934d26aba512e17c939f45",
            "value": 1
          }
        },
        "8bc22ca988f04e13bd6c81d330380007": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e5f0b71af9e4ed69175de5547695a12",
            "placeholder": "​",
            "style": "IPY_MODEL_e2c2fba5942e42dba8cb29e73bf2c86d",
            "value": " 36/0 [00:00&lt;00:00, 183.48 examples/s]"
          }
        },
        "1437800607304bcdaf96b0ac4a0dc7ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5231f813a803401ebc5126d3881d751b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c403273055f40c2b834aba1e8c77314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b87fcc0d692f4632b6870adeb52a1baa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9aa9352ca1934d26aba512e17c939f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e5f0b71af9e4ed69175de5547695a12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2c2fba5942e42dba8cb29e73bf2c86d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f0d641831fd494e8be9301faf295821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4705c0ab3d704dc68af6ff3ff0cfa218",
              "IPY_MODEL_4b247b4d649b45eb994d1d2ce2064cac",
              "IPY_MODEL_b1a9d5f3adab420bbb5c721631536320"
            ],
            "layout": "IPY_MODEL_2ff39d0c66154733b23c9a2c0a3c4199"
          }
        },
        "4705c0ab3d704dc68af6ff3ff0cfa218": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7bda80aaf5448f5a7fe5f42ea99df10",
            "placeholder": "​",
            "style": "IPY_MODEL_4ec3d129934f4975aab12b310f374251",
            "value": "Map: 100%"
          }
        },
        "4b247b4d649b45eb994d1d2ce2064cac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b655e70abf1c4dcabaf06748aa51120a",
            "max": 36,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62fcd00bfbc642ee930a7caf77484062",
            "value": 36
          }
        },
        "b1a9d5f3adab420bbb5c721631536320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c50de825116e4cc4acad164a8d84885f",
            "placeholder": "​",
            "style": "IPY_MODEL_2189a7b7f47d414991a0b072470e940a",
            "value": " 36/36 [00:00&lt;00:00, 227.35 examples/s]"
          }
        },
        "2ff39d0c66154733b23c9a2c0a3c4199": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7bda80aaf5448f5a7fe5f42ea99df10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ec3d129934f4975aab12b310f374251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b655e70abf1c4dcabaf06748aa51120a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62fcd00bfbc642ee930a7caf77484062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c50de825116e4cc4acad164a8d84885f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2189a7b7f47d414991a0b072470e940a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzNwcWkfMtdq"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UloA4rNdM81N",
        "outputId": "7a55c632-eccc-474c-b164-9242187a62a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.0.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.0.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n"
      ],
      "metadata": {
        "id": "QaclAcNENGTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "data = [\n",
        "  {\"prompt\": \"What is the current temperature in the living room?\", \"response\": \"22°C\"},\n",
        "  {\"prompt\": \"Is the front door currently locked?\", \"response\": \"true\"},\n",
        "  {\"prompt\": \"When was the last time the kitchen lights were turned on?\", \"response\": \"2023-12-25 18:30:00\"},\n",
        "  {\"prompt\": \"What is the current humidity level in the bedroom?\", \"response\": \"45%\"},\n",
        "  {\"prompt\": \"How much energy did the dishwasher consume during its last cycle?\", \"response\": \"0.8 kWh\"},\n",
        "  {\"prompt\": \"Is the garage door currently open?\", \"response\": \"false\"},\n",
        "  {\"prompt\": \"What is the current battery level of the smoke detector in the hallway?\", \"response\": \"85%\"},\n",
        "  {\"prompt\": \"When was the last time the sprinkler system was activated?\", \"response\": \"2023-12-20 10:00:00\"},\n",
        "  {\"prompt\": \"What is the current air quality index in the living room?\", \"response\": \"75\"},\n",
        "  {\"prompt\": \"How many times has the doorbell rung today?\", \"response\": \"3\"},\n",
        "  {\"prompt\": \"When was the last time the security system was armed?\", \"response\": \"2023-12-25 22:00:00\"},\n",
        "  {\"prompt\": \"What is the current water temperature of the hot water heater?\", \"response\": \"60°C\"},\n",
        "  {\"prompt\": \"How many hours has the air conditioner been running today?\", \"response\": \"4\"},\n",
        "  {\"prompt\": \"Is the refrigerator door currently open?\", \"response\": \"false\"},\n",
        "  {\"prompt\": \"When was the last time the oven was used?\", \"response\": \"2023-12-23 17:00:00\"},\n",
        "  {\"prompt\": \"What is the current CO2 level in the bedroom?\", \"response\": \"400 ppm\"},\n",
        "  {\"prompt\": \"How much energy has the washing machine consumed this month?\", \"response\": \"30 kWh\"},\n",
        "  {\"prompt\": \"Is the fireplace currently on?\", \"response\": \"false\"},\n",
        "  {\"prompt\": \"When was the last time the blinds in the living room were closed?\", \"response\": \"2023-12-25 16:00:00\"},\n",
        "  {\"prompt\": \"What is the current temperature outside?\", \"response\": \"10°C\"},\n",
        "   {\n",
        "    \"prompt\": \"Q: How many windows are currently open?\\nLet's think step by step:\\nFirst, check each room. There are 2 windows open in the bedroom and 1 in the living room. That makes a total of 3 windows.\",\n",
        "    \"response\": \"3\"\n",
        "  },\n",
        "  # for chain of thought prompting\n",
        "  {\n",
        "    \"prompt\": \"Q: How much energy did the air conditioner use today?\\nLet's think step by step:\\n- First, let's check how long the air conditioner has been running.\\n- The air conditioner has been running for 5 hours today.\\n- Next, we check the power consumption rate of the air conditioner.\\n- The air conditioner uses 1.2 kWh per hour.\\n- Now, multiply the running hours by the energy usage rate: 5 × 1.2 = 6 kWh.\\nSo, the air conditioner used 6 kWh of energy today.\",\n",
        "    \"response\": \"6 kWh\"\n",
        "  },\n",
        "  {\n",
        "    \"prompt\": \"Q: When was the last time the sprinkler system was activated?\\nLet's break it down:\\n- First, we need to check the activity log for the sprinkler system.\\n- The last activation was recorded on December 20, 2023, at 10:00 AM.\\nSo, the sprinkler system was last activated on December 20, 2023, at 10:00 AM.\",\n",
        "    \"response\": \"December 20, 2023, at 10:00 AM\"\n",
        "  },\n",
        "  {\n",
        "    \"prompt\": \"Q: What is the current battery level of the smoke detector in the hallway?\\nLet's think step by step:\\n- First, we check the battery status of the smoke detector in the hallway.\\n- The current battery level is 85%.\\nSo, the smoke detector's battery is 85% charged, which means it is functioning properly.\",\n",
        "    \"response\": \"85%\"\n",
        "  },\n",
        "  {\n",
        "    \"prompt\": \"Q: How much energy did the dishwasher consume during its last cycle?\\nLet's think step by step:\\n- First, check how long the last dishwasher cycle ran.\\n- The dishwasher cycle lasted for 1.5 hours.\\n- Next, we check the power consumption rate of the dishwasher.\\n- The dishwasher consumes 0.8 kWh per hour.\\n- Now, multiply the time by the energy rate: 1.5 × 0.8 = 1.2 kWh.\\nSo, the dishwasher consumed 1.2 kWh during its last cycle.\",\n",
        "    \"response\": \"1.2 kWh\"\n",
        "  },\n",
        "  {\n",
        "    \"prompt\": \"Q: Is the security system currently armed?\\nLet's think step by step:\\n- First, check the current status of the security system.\\n- The security system log shows that it was armed at 10:00 PM last night.\\n- Since no disarm action has been recorded since then, the system is still armed.\\nSo, yes, the security system is currently armed.\",\n",
        "    \"response\": \"Yes\"\n",
        "  },\n",
        "  {\n",
        "    \"prompt\": \"Q: Is the garage door currently open?\\nLet's break it down:\\n- First, we need to check the current status of the garage door sensor.\\n- The sensor indicates that the door is closed.\\nSo, no, the garage door is not currently open.\",\n",
        "    \"response\": \"No\"\n",
        "  },\n",
        "  {\n",
        "    \"prompt\": \"Q: When was the last time the oven was used?\\nLet's think step by step:\\n- First, check the activity log of the oven.\\n- The log shows that the oven was last turned on at 5:00 PM on December 23, 2023.\\nSo, the oven was last used at 5:00 PM on December 23, 2023.\",\n",
        "    \"response\": \"December 23, 2023, at 5:00 PM\"\n",
        "  },\n",
        "  {\n",
        "    \"prompt\": \"Q: What is the current water temperature of the hot water heater?\\nLet's break it down:\\n- First, check the current temperature reading from the hot water heater.\\n- The water heater is currently set to 60°C.\\nSo, the current water temperature is 60°C.\",\n",
        "    \"response\": \"60°C\"\n",
        "  },\n",
        "  {\n",
        "    \"prompt\": \"Q: When were the blinds in the living room last closed?\\nLet's think step by step:\\n- First, check the log of the smart blinds in the living room.\\n- The blinds were last closed at 4:00 PM on December 25, 2023.\\nSo, the blinds were last closed at 4:00 PM on December 25, 2023.\",\n",
        "    \"response\": \"December 25, 2023, at 4:00 PM\"\n",
        "  },\n",
        "  {\n",
        "    \"prompt\": \"Q: What is the current CO2 level in the bedroom?\\nLet's break it down:\\n- First, check the CO2 sensor in the bedroom.\\n- The sensor is reading a CO2 level of 400 ppm.\\nSo, the current CO2 level in the bedroom is 400 ppm, which is within the normal range.\",\n",
        "    \"response\": \"400 ppm\"\n",
        "  },\n",
        "  {\n",
        "    \"prompt\": \"Q: What is the current air quality index in the living room?\\nLet's think step by step:\\n- First, check the air quality sensor in the living room.\\n- The air quality index (AQI) is reading 75.\\n- According to AQI standards, this is in the 'Moderate' range.\\nSo, the air quality in the living room is moderate with an AQI of 75.\",\n",
        "    \"response\": \"75\"\n",
        "  },\n",
        "  {\n",
        "    \"prompt\": \"Q: Is the refrigerator door currently open?\\nLet's break it down:\\n- First, check the current status of the refrigerator door sensor.\\n- The sensor indicates that the door is closed.\\nSo, no, the refrigerator door is not currently open.\",\n",
        "    \"response\": \"No\"\n",
        "  },\n",
        "  {\n",
        "    \"prompt\": \"Q: How much energy has the washing machine consumed this month?\\nLet's think step by step:\\n- First, check the washing machine’s energy log for this month.\\n- The washing machine has consumed 30 kWh so far this month.\\nSo, the washing machine has used 30 kWh of energy this month.\",\n",
        "    \"response\": \"30 kWh\"\n",
        "  },\n",
        "  {\n",
        "    \"prompt\": \"Q: How many devices are currently connected to the smart home system?\\nLet's break it down:\\n- First, check the network or hub to see how many devices are currently online.\\n- There are 15 devices currently connected to the smart home network.\\nSo, 15 devices are currently online.\",\n",
        "    \"response\": \"15 devices\"\n",
        "  },\n",
        "  {\n",
        "    \"prompt\": \"Q: How many lights are currently turned on in the house?\\nLet's think step by step:\\n- First, check the status of all connected smart lights.\\n- 2 lights are on in the kitchen, and 1 light is on in the living room.\\n- So, there are 3 lights currently on in the house.\\nSo, 3 lights are currently turned on.\",\n",
        "    \"response\": \"3 lights\"\n",
        "  }\n",
        "\n",
        "]\n",
        "\n",
        "with open('iot_dataset.json', 'w') as f:\n",
        "    json.dump(data, f)\n"
      ],
      "metadata": {
        "id": "NWBtLQL-NIrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hx_kFs9PbKLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset('json',data_files='iot_dataset.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "14554b1f9c4c4e369a3ba3bba88dc14a",
            "05dc222f99cc46ed87929aad87be1076",
            "946320ac58514a08a122f47dd66e32c3",
            "8bc22ca988f04e13bd6c81d330380007",
            "1437800607304bcdaf96b0ac4a0dc7ae",
            "5231f813a803401ebc5126d3881d751b",
            "8c403273055f40c2b834aba1e8c77314",
            "b87fcc0d692f4632b6870adeb52a1baa",
            "9aa9352ca1934d26aba512e17c939f45",
            "5e5f0b71af9e4ed69175de5547695a12",
            "e2c2fba5942e42dba8cb29e73bf2c86d"
          ]
        },
        "id": "u0Rlv_JTNQOv",
        "outputId": "d42f1b2c-5c8f-43f2-810b-0ee46a958690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14554b1f9c4c4e369a3ba3bba88dc14a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer ,Seq2SeqTrainingArguments\n",
        "model_name = 'google/flan-t5-base'\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "tokenizer =AutoTokenizer.from_pretrained(model_name)\n",
        "\n"
      ],
      "metadata": {
        "id": "hJdQ8ns7Ndzo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b0948bc-5c78-4777-bdd7-35add8244ede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    inputs = examples['prompt']\n",
        "    targets = examples['response']\n",
        "    model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding=\"max_length\")\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # Ensure the lengths are the same\n",
        "    if len(model_inputs[\"input_ids\"]) != len(labels[\"input_ids\"]):\n",
        "        raise ValueError(f\"Input and label lengths do not match: {len(model_inputs['input_ids'])} vs {len(labels['input_ids'])}\")\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Wjn0OKzbOmwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict"
      ],
      "metadata": {
        "id": "SbGFA7KpU6X4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Inspect the dataset\n",
        "print(tokenized_dataset['train'][0])  # Inspect a sample\n",
        "\n",
        "\n",
        "\n",
        "# Split dataset if necessary\n",
        "if 'validation' not in tokenized_dataset:\n",
        "    train_valid_split = tokenized_dataset['train'].train_test_split(test_size=0.1)\n",
        "    tokenized_dataset = DatasetDict({\n",
        "        'train': train_valid_split['train'],\n",
        "        'validation': train_valid_split['test']\n",
        "    })\n",
        "\n",
        "# Verify the splits\n",
        "print(tokenized_dataset)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=1,\n",
        "    num_train_epochs=3,\n",
        "    predict_with_generate=True,\n",
        ")\n",
        "\n",
        "# Initialize the trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset['train'],\n",
        "    eval_dataset=tokenized_dataset['validation'],\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516,
          "referenced_widgets": [
            "1f0d641831fd494e8be9301faf295821",
            "4705c0ab3d704dc68af6ff3ff0cfa218",
            "4b247b4d649b45eb994d1d2ce2064cac",
            "b1a9d5f3adab420bbb5c721631536320",
            "2ff39d0c66154733b23c9a2c0a3c4199",
            "b7bda80aaf5448f5a7fe5f42ea99df10",
            "4ec3d129934f4975aab12b310f374251",
            "b655e70abf1c4dcabaf06748aa51120a",
            "62fcd00bfbc642ee930a7caf77484062",
            "c50de825116e4cc4acad164a8d84885f",
            "2189a7b7f47d414991a0b072470e940a"
          ]
        },
        "id": "0LWYNZLSSOxU",
        "outputId": "f9bc1ee9-50b3-43d3-b8fa-ca0dce7fcf37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/36 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f0d641831fd494e8be9301faf295821"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:4126: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'prompt': 'What is the current temperature in the living room?', 'response': '22°C', 'input_ids': [363, 19, 8, 750, 2912, 16, 8, 840, 562, 58, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [1630, 1956, 254, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['prompt', 'response', 'input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 32\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['prompt', 'response', 'input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 4\n",
            "    })\n",
            "})\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [24/24 08:39, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>48.681328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>44.627777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>43.387573</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=24, training_loss=43.100067138671875, metrics={'train_runtime': 546.525, 'train_samples_per_second': 0.176, 'train_steps_per_second': 0.044, 'total_flos': 16434176458752.0, 'train_loss': 43.100067138671875, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('./fine-tuned-flan-t5-iot')\n",
        "tokenizer.save_pretrained('./fine-tuned-flan-t5-iot')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ri1bHRr3XW4w",
        "outputId": "0b0726d9-140d-4d90-90e0-2462c23c8c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./fine-tuned-flan-t5-iot/tokenizer_config.json',\n",
              " './fine-tuned-flan-t5-iot/special_tokens_map.json',\n",
              " './fine-tuned-flan-t5-iot/spiece.model',\n",
              " './fine-tuned-flan-t5-iot/added_tokens.json',\n",
              " './fine-tuned-flan-t5-iot/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\"What is the current temperature reported by the greenhouse sensor?\", return_tensors=\"pt\")\n",
        "outputs = model.generate(**inputs)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N51cjPZWyxbJ",
        "outputId": "55cbfa5b-e384-4181-8b31-fc97bb78c5f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 °C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\"What is the current temperature reported by the greenhouse sensor?\", return_tensors=\"pt\")\n",
        "outputs = model.generate(**inputs)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5fNlD1aXpoo",
        "outputId": "4158f6f6-512d-43ee-ed62-5c7801eeb04c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 °C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\"Is the fireplace currently on?\", return_tensors=\"pt\")\n",
        "outputs = model.generate(**inputs)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PY3rxvtDayJv",
        "outputId": "e41002e4-3cac-4790-a82e-23c4fe36c142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The fireplace is still on.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\"How many times has the doorbell rung today?\", return_tensors=\"pt\")\n",
        "outputs = model.generate(**inputs)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwVm1GcnbMU_",
        "outputId": "1df6f65b-61b9-4424-a67f-c9757034afef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ten\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the prompt for zero-shot inference\n",
        "\n",
        "prompt = \"Is the front door currently locked?\"\n",
        "\n",
        "# Tokenize the input\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# Generate output from the model\n",
        "output = model.generate(**inputs)\n",
        "\n",
        "# Decode the output\n",
        "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(\"Zero-shot response:\", response)"
      ],
      "metadata": {
        "id": "175NGTYhbfFc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c30331a1-4ba5-4a0a-9485-3e67900cbfdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero-shot response: no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the prompt with one-shot example\n",
        "prompt = \"\"\"\n",
        "Example:\n",
        "Q: Is the front door currently locked?\n",
        "A: True\n",
        "\n",
        "Now answer:\n",
        "Q: Is the garage door currently open?\n",
        "A:\"\"\"\n",
        "\n",
        "# Tokenize and generate output\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "output = model.generate(**inputs)\n",
        "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(\"One-shot response:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayF8l2m91p_Z",
        "outputId": "9bfa5d29-4ea7-41c6-8fc7-024555c8dab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-shot response: No\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the prompt with few-shot examples\n",
        "prompt = \"\"\"\n",
        "Examples:\n",
        "Q: Is the front door currently locked?\n",
        "A: True\n",
        "\n",
        "Q: When was the last time the kitchen lights were turned on?\n",
        "A: 2023-12-25 18:30:00\n",
        "\n",
        "Q: What is the current humidity level in the bedroom?\n",
        "A: 45%\n",
        "\n",
        "Now answer:\n",
        "Q: Is the garage door currently open?\n",
        "A:\"\"\"\n",
        "\n",
        "# Tokenize and generate output\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "output = model.generate(**inputs)\n",
        "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(\"Few-shot response:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXXqARdz1xG0",
        "outputId": "cb121097-59d0-4b6f-c1c8-8a08cef721aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Few-shot response: No\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# chain of thought prompting\n",
        "\n",
        "prompt = \"\"\"\n",
        "Q: How many windows are currently open?\n",
        "Let's think step by step:\n",
        "- There are 2 windows open in the bedroom.\n",
        "- There is 1 window open in the living room.\n",
        "So, in total, there are 3 windows open.\n",
        "\n",
        "Q: What is 23 + 19?\n",
        "Let's break it down step by step:\n",
        "- First, add 20 to 23 to get 43.\n",
        "- Then, subtract 1 from 43 to get 42.\n",
        "So, the answer is 42.\n",
        "\n",
        "Q: How much is 12 + 15?\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize and generate input\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "output = model.generate(**inputs)\n",
        "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(\"Few-shot response:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbJZS6_nAnW4",
        "outputId": "b2aef7fa-023f-413a-f8cc-aec897d61b3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Few-shot response: Let's break it down step by step: 12 + 15 = 12 + 15. So,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chain of Thought prompting\n",
        "\n",
        "prompt = \"\"\"\n",
        "Q: How many windows are currently open?\n",
        "Let's think step by step:\n",
        "- There are 2 windows open in the bedroom.\n",
        "- There is 1 window open in the living room.\n",
        "So, in total, there are 3 windows open.\n",
        "\n",
        "\n",
        "Q: How many windows are open in bedroom ?\n",
        "\"\"\"\n",
        "\n",
        "inputs =tokenizer(prompt,return_tensors=\"pt\")\n",
        "output =model.generate(**inputs)\n",
        "response = tokenizer.decode(output[0],skip_special_tokens=True)\n",
        "print(\"following is response\",response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRZqpIWJBCu5",
        "outputId": "e809294d-3ec5-4ab6-edb8-0b827fa93e31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "following is response There are 2 windows in the bedroom. There are 1 window in the living room. So,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dd = []\n",
        "dd.append(\"device-id\")\n",
        "dd.append(\"device-name\")\n",
        "dd.append(\"action\")\n",
        "dd.append(\"time\")\n",
        "print(dd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjGREXk1inPC",
        "outputId": "31e683c2-8182-4b6d-e62e-7276b092376b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['device-id', 'device-name', 'action', 'time']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dd.append([1,\"fridge\",\"opened by skand\",\"timeing was 12 pm\"])\n",
        "dd.append([2,\"AC\",\"Ac was closed by itself\",\"time do not know\"])\n",
        "dd.append([3,\"tv\",\"someone broke the tv\",\"around 1 pm\"])\n",
        "dd.append([1,\"fridge\",\"closed by kartikey\",\"around 1 am\"])\n",
        "print(dd)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYqe6n8AjNQJ",
        "outputId": "6ce7b1b4-1182-43b1-eea4-056ea8f8f97f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['device-id', 'device-name', 'action', 'time', [1, 'fridge', 'opened by skand', 'timeing was 12 pm'], [2, 'AC', 'Ac was closed by itself', 'time do not know'], [1, 'fridge', 'opened by skand', 'timeing was 12 pm'], [2, 'AC', 'Ac was closed by itself', 'time do not know'], [3, 'tv', 'someone broke the tv', 'around 1 pm'], [1, 'fridge', 'closed by kartikey', 'around 1 am']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a DataFrame with named columns\n",
        "data = {\n",
        "    'a': np.random.rand(10),\n",
        "    'b': np.random.rand(10),\n",
        "    'c': np.random.rand(10),\n",
        "    'd': np.random.rand(10)\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ub8JlznlnfF3",
        "outputId": "d9834bad-c49f-4eee-ae03-bf87250cef1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          a         b         c         d\n",
            "0  0.941745  0.578464  0.663583  0.152333\n",
            "1  0.147970  0.453929  0.720844  0.936473\n",
            "2  0.069154  0.757662  0.654975  0.834616\n",
            "3  0.188173  0.147196  0.084091  0.276709\n",
            "4  0.018959  0.418186  0.794336  0.097255\n",
            "5  0.960065  0.353291  0.659867  0.925461\n",
            "6  0.875143  0.176070  0.599552  0.455794\n",
            "7  0.443537  0.525922  0.684938  0.637891\n",
            "8  0.030747  0.192463  0.134609  0.695478\n",
            "9  0.275135  0.831272  0.311929  0.660853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data ={\"device-id\":[],\"device-name\":[],\"action\":[],\"time\":[]}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCr0nByDptbH",
        "outputId": "be9dea0b-3bf2-4a95-8ea2-8986c767fd05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [device-id, device-name, action, time]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)\n",
        "print(len(df))\n",
        "print(df.shape)\n",
        "df.append([1,\"fridge\",\"opened by skand\",\"timeing was 12 pm\"])\n",
        "df.append([2,\"AC\",\"Ac was closed by itself\",\"time do not know\"])\n",
        "df.append([3,\"tv\",\"someone broke the tv\",\"around 1 pm\"])\n",
        "df.append([1,\"fridge\",\"closed by kartikey\",\"around 1 am\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "2GRWMwuGp6ol",
        "outputId": "80819478-9b5d-4e79-e617-d34cab172d78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['device-id', 'device-name', 'action', 'time'], dtype='object')\n",
            "0\n",
            "(0, 4)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DataFrame' object has no attribute 'append'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-8513963eb5ac>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"fridge\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"opened by skand\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"timeing was 12 pm\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"AC\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Ac was closed by itself\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"time do not know\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"tv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"someone broke the tv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"around 1 pm\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6202\u001b[0m         ):\n\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6206\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l=[-25.82501623,\t-30.07508668,\n",
        "-37.42527197,\t-32.16880981,\n",
        "-35.43773516,\t-45.03983221,\n",
        "-28.52476296,\t-39.18457302,\n",
        "-32.67371628,\t-35.15226686,\n",
        "-48.38727906,\t-43.788397,\n",
        "-21.41928125,\t-52.5096872,\n",
        "-32.23220943,\t-38.4035275,\n",
        "-32.67784108,\t-42.47122021,\n",
        "-35.43773516,\t-39.55945656]\n",
        "\n",
        "a=0\n",
        "b=0\n",
        "for i in range(0,len(l)):\n",
        "  if(i%2==0):\n",
        "    a+=l[i]\n",
        "  else:\n",
        "    b+=l[i]\n",
        "print(2*a/len(l))\n",
        "print(2*b/len(l))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka3jab2oFZa4",
        "outputId": "7e780a9f-118c-4941-ea06-534ad4d5e176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-33.004084858\n",
            "-39.835285705000004\n"
          ]
        }
      ]
    }
  ]
}